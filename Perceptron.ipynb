{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer perceptron. Stochastic gradient descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Класс перцептрона\n",
    "Вход            -   столбец $ W_{in} \\;[ 784 \\times 1] $, $ 784 = 28 \\times 28 $ -- размер исходного изображения  \n",
    "Первый слой     -   столбец $ S_{1} \\; [16 \\times 1] $  \n",
    "Второй слой     -   столбец $ S_{2} \\; [10 \\times 1] $  \n",
    "Выходной слой   -   столбец $ W_{out} \\; [10 \\times 1] $  \n",
    "В выходном слое в элементе $W_{out}[i], i \\in [0,9]$ содержится оценка вероятности того, что на вход подано изображение числа $i$  \n",
    "В качестве функции активации используется сигмоида $\\sigma (x) = \\frac{1}{1 + e^{-x}}$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "class Perceptron:\n",
    "    # INFO\n",
    "    # Matrix sizes\n",
    "\n",
    "    # s_in:  [w_in_dim  x 1        ]\n",
    "    # w_1:   [w_1_dim   x w_in_dim ]\n",
    "    # w_2:   [w_2_dim   x w_1_dim  ]\n",
    "    # w_3:   [w_out_dim x w_2_dim  ]\n",
    "    # s_out: [w_out_dim x 1        ]\n",
    "\n",
    "    s_in_dim = 0  # size of input vector\n",
    "    w_1_dim = 0  # number of rows in 1st hidden layer\n",
    "    w_2_dim = 0  # number of rows in 2nd hidden layer\n",
    "    s_out_dim = 0  # size of output vector\n",
    "\n",
    "    layers = []  # [w_1, w_2, w_3]\n",
    "    w_1 = []  # matrix with coefficients in ->  1\n",
    "    w_2 = []  # matrix with coefficients 1  ->  2\n",
    "    w_3 = []  # matrix with coefficients 2  ->  out\n",
    "\n",
    "    delta_w_1 = []\n",
    "    delta_w_2 = []\n",
    "    delta_w_3 = []\n",
    "\n",
    "    eta = 0\n",
    "    test_num = 0  # 0 in the beginning of learning. Increases when picture is processed\n",
    "    epoch_num = 0  # 0 in the beginning of learning. Increases when the whole battery of test pictures is processed\n",
    "\n",
    "    error = []  # array of errors of all the tests\n",
    "\n",
    "    def act_func(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def __init__(self, s_in_dim, w_1_dim, w_2_dim, s_out_dim, is_continuation):\n",
    "        if is_continuation:\n",
    "            self.load_changes()\n",
    "        else:\n",
    "            self.s_in_dim = s_in_dim\n",
    "            self.w_1_dim = w_1_dim\n",
    "            self.w_2_dim = w_2_dim\n",
    "            self.s_out_dim = s_out_dim\n",
    "\n",
    "            self.w_1 = np.random.sample((w_1_dim, s_in_dim)) / 10000\n",
    "            self.w_2 = np.random.sample((w_2_dim, w_1_dim)) / 100\n",
    "            self.w_3 = np.random.sample((s_out_dim, w_2_dim)) / 10\n",
    "\n",
    "            self.delta_w_1 = np.zeros((w_1_dim, s_in_dim))\n",
    "            self.delta_w_2 = np.zeros((w_2_dim, w_1_dim))\n",
    "            self.delta_w_3 = np.zeros((s_out_dim, w_2_dim))\n",
    "\n",
    "            self.layers = [self.w_1, self.w_2, self.w_3]\n",
    "\n",
    "    def recognize(self, picture):\n",
    "        s_1 = self.act_func(self.w_1 @ picture)\n",
    "        s_2 = self.act_func(self.w_2 @ s_1)\n",
    "        s_out = self.act_func(self.w_3 @ s_2)\n",
    "        return np.argmax(s_out)\n",
    "\n",
    "    def get_output(self, picture):\n",
    "        picture = np.array(picture).reshape((len(picture), 1)) / 255\n",
    "        s_1 = self.act_func(self.w_1 @ picture)\n",
    "        s_2 = self.act_func(self.w_2 @ s_1)\n",
    "        s_out = self.act_func(self.w_3 @ s_2)\n",
    "        return s_out\n",
    "\n",
    "    def errf(self, picture, ans):\n",
    "        picture = np.array(picture).reshape((len(picture), 1)) / 255\n",
    "        s_1 = self.act_func(self.w_1 @ picture)\n",
    "        s_2 = self.act_func(self.w_2 @ s_1)\n",
    "        s_out = self.act_func(self.w_3 @ s_2)\n",
    "\n",
    "        indicators = np.zeros(self.s_out_dim)\n",
    "        indicators[ans] = 1\n",
    "\n",
    "        return np.linalg.norm(indicators - s_out) / 2\n",
    "\n",
    "    def errf_with_custom_weights(self, picture, ans, w_1, w_2, w_3):\n",
    "        picture = np.array(picture).reshape((len(picture), 1)) / 255\n",
    "        s_1 = self.act_func(w_1 @ picture)\n",
    "        s_2 = self.act_func(w_2 @ s_1)\n",
    "        s_out = self.act_func(w_3 @ s_2)\n",
    "\n",
    "        indicators = np.zeros(self.s_out_dim)\n",
    "        indicators[ans] = 1\n",
    "\n",
    "        return np.linalg.norm(indicators - s_out) / 2\n",
    "\n",
    "    def get_grad(self, picture, ans):\n",
    "        picture = np.array(picture).reshape((len(picture), 1)) / 255\n",
    "        s_1 = self.act_func(self.w_1 @ picture)\n",
    "        s_2 = self.act_func(self.w_2 @ s_1)\n",
    "        s_out = self.act_func(self.w_3 @ s_2)\n",
    "\n",
    "        indicators = np.zeros(self.s_out_dim)\n",
    "        indicators[ans] = 1\n",
    "\n",
    "        delta_3 = s_out * (s_out - np.ones(self.s_out_dim).reshape((self.s_out_dim, 1))) * (\n",
    "                indicators.reshape((self.s_out_dim, 1)) - s_out)\n",
    "        delta_2 = s_2 * (np.ones(len(s_2)).reshape((len(s_2), 1)) - s_2) * (self.w_3.T @ delta_3)\n",
    "        delta_1 = s_1 * (np.ones(len(s_1)).reshape((len(s_1), 1)) - s_1) * (self.w_2.T @ delta_2)\n",
    "\n",
    "        grad_w_3 = (s_2.reshape((self.w_2_dim, 1)) @ delta_3.reshape((1, self.s_out_dim))).T\n",
    "        grad_w_2 = (self.eta * s_1.reshape((self.w_1_dim, 1)) @ delta_2.reshape((1, self.w_2_dim))).T\n",
    "        grad_w_1 = (self.eta * picture @ delta_1.reshape((1, self.w_1_dim))).T\n",
    "\n",
    "        return grad_w_1, grad_w_2, grad_w_3\n",
    "\n",
    "    def back_propagation(self, picture, ans, alpha):\n",
    "        picture = np.array(picture).reshape((len(picture), 1)) / 255\n",
    "        s_1 = self.act_func(self.w_1 @ picture)\n",
    "        s_2 = self.act_func(self.w_2 @ s_1)\n",
    "        s_out = self.act_func(self.w_3 @ s_2)\n",
    "\n",
    "        indicators = np.zeros(self.s_out_dim)\n",
    "        indicators[ans] = 1\n",
    "\n",
    "        delta_3 = s_out * (s_out - np.ones(self.s_out_dim).reshape((self.s_out_dim, 1))) * (\n",
    "                indicators.reshape((self.s_out_dim, 1)) - s_out)\n",
    "        delta_2 = s_2 * (np.ones(len(s_2)).reshape((len(s_2), 1)) - s_2) * (self.w_3.T @ delta_3)\n",
    "        delta_1 = s_1 * (np.ones(len(s_1)).reshape((len(s_1), 1)) - s_1) * (self.w_2.T @ delta_2)\n",
    "\n",
    "        self.delta_w_3 = alpha * self.delta_w_3 + \\\n",
    "                         ((1 - alpha) * self.eta * s_2.reshape((self.w_2_dim, 1)) @ delta_3.reshape(\n",
    "                             (1, self.s_out_dim))).T\n",
    "        self.delta_w_2 = alpha * self.delta_w_2 + \\\n",
    "                         ((1 - alpha) * self.eta * s_1.reshape((self.w_1_dim, 1)) @ delta_2.reshape(\n",
    "                             (1, self.w_2_dim))).T\n",
    "        self.delta_w_1 = alpha * self.delta_w_1 + \\\n",
    "                         ((1 - alpha) * self.eta * picture @ delta_1.reshape((1, self.w_1_dim))).T\n",
    "\n",
    "        self.w_3 -= self.delta_w_3\n",
    "        self.w_2 -= self.delta_w_2\n",
    "        self.w_1 -= self.delta_w_1\n",
    "\n",
    "        self.error.append(np.linalg.norm(indicators - s_out) / 2)\n",
    "\n",
    "    def get_data(self):\n",
    "        with open(\"perceptron_data.json\", \"r\") as read_file:\n",
    "            data = json.load(read_file)\n",
    "            # update data\n",
    "            data[\"s_in_dim\"] = Perceptron.s_in_dim\n",
    "            data[\"w_1_dim\"] = Perceptron.w_1_dim\n",
    "            data[\"w_2_dim\"] = Perceptron.w_2_dim\n",
    "            data[\"s_out_dim\"] = Perceptron.s_out_dim\n",
    "            data[\"layers\"] = Perceptron.layers\n",
    "            data[\"w_1\"] = Perceptron.w_1\n",
    "            data[\"w_2\"] = Perceptron.w_2\n",
    "            data[\"w_3\"] = Perceptron.w_3\n",
    "            data[\"delta_w_1\"] = Perceptron.delta_w_1\n",
    "            data[\"delta_w_2\"] = Perceptron.delta_w_2\n",
    "            data[\"delta_w_3\"] = Perceptron.delta_w_3\n",
    "            data[\"eta\"] = Perceptron.eta\n",
    "            data[\"test_num\"] = Perceptron.test_num\n",
    "            data[\"epoch_num\"] = Perceptron.epoch_num\n",
    "            data[\"error\"] = Perceptron.error\n",
    "        return data\n",
    "\n",
    "    \n",
    "    def initial_state():\n",
    "        initial_state_dict = {\n",
    "        \"s_in_dim\": 0,\n",
    "        \"w_1_dim\": 0,\n",
    "        \"w_2_dim\": 0,\n",
    "        \"s_out_dim\": 0,\n",
    "        \"layers\": [],\n",
    "        \"w_1\": [],\n",
    "        \"w_2\": [],\n",
    "        \"w_3\": [],\n",
    "        \"delta_w_1\": [],\n",
    "        \"delta_w_2\": [],\n",
    "        \"delta_w_3\": [],\n",
    "        \"eta\": 0,\n",
    "        \"test_num\": 0,\n",
    "        \"epoch_num\": 0,\n",
    "        \"error\": []\n",
    "        }\n",
    "        return initial_state_dict\n",
    "    \n",
    "    \n",
    "    def save_state(self):\n",
    "        if os.path.exists(\"perceptron_data.json\"):\n",
    "            data = get_data(self)\n",
    "            with open(\"data_file4.json\", \"w\") as write_file:\n",
    "                write_file.write(json.dumps(data))\n",
    "        else:\n",
    "            with open(\"perceptron_data.json\", \"w\") as write_file:\n",
    "                write_file.write(json.dumps(initial_state))\n",
    "            data = get_data(self)\n",
    "            with open(\"data_file4.json\", \"w\") as write_file:\n",
    "                write_file.write(json.dumps(data))\n",
    "\n",
    "\n",
    "    def load_state(self):\n",
    "        with open(\"data_file4.json\", \"r\") as read_file:\n",
    "            data = json.load(read_file)\n",
    "            Perceptron.s_in_dim = data[\"s_in_dim\"]\n",
    "            Perceptron.w_1_dim = data[\"w_1_dim\"]\n",
    "            Perceptron.w_2_dim = data[\"w_2_dim\"]\n",
    "            Perceptron.s_out_dim = data[\"s_out_dim\"]\n",
    "            Perceptron.layers = data[\"layers\"]\n",
    "            Perceptron.w_1 = data[\"w_1\"]\n",
    "            Perceptron.w_2 = data[\"w_2\"]\n",
    "            Perceptron.w_3 = data[\"w_3\"]\n",
    "            Perceptron.delta_w_1 = data[\"delta_w_1\"]\n",
    "            Perceptron.delta_w_2 = data[\"delta_w_2\"]\n",
    "            Perceptron.delta_w_3 = data[\"delta_w_3\"]\n",
    "            Perceptron.eta = data[\"eta\"]\n",
    "            Perceptron.test_num = data[\"test_num\"]\n",
    "            Perceptron.epoch_num = data[\"epoch_num\"]\n",
    "            Perceptron.error = data[\"error\"]\n",
    "    def update_weights(self, grad_w_1, grad_w_2, grad_w_3, step):\n",
    "        self.w_1 -= step * grad_w_1\n",
    "        self.w_2 -= step * grad_w_2\n",
    "        self.w_3 -= step * grad_w_3\n",
    "\n",
    "    def teach_stochastic(self, epochs_num):\n",
    "        mndata = MNIST('samples')\n",
    "        images, labels = mndata.load_testing()\n",
    "\n",
    "        self.load_changes()\n",
    "        data = zip(images, labels)\n",
    "\n",
    "        for epoch in range(epochs_num):\n",
    "            self.eta = 1 / (self.epoch_num ** (1 / 2) + 1)\n",
    "            for image, label in data:\n",
    "                self.back_propagation(image, label, 0.1)\n",
    "                self.test_num += 1\n",
    "            self.save_changes()\n",
    "            self.epoch_num += 1\n",
    "            # self.test_num = 0\n",
    "            print('Epoch {} processed, error = {}'.format(self.epoch_num, self.error[-1]))\n",
    "\n",
    "            idx = np.linspace(0, len(images) - 1, len(images))\n",
    "            new_img = [images[int(idx[i])] for i in range(len(idx))]\n",
    "            new_lbl = [labels[int(idx[i])] for i in range(len(idx))]\n",
    "            data = zip(new_img, new_lbl)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        x = range(len(self.error))\n",
    "        y = self.error\n",
    "        ax.plot(x, y, label='Значение функции ошибок')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "    def teach_batch(self, epochs_num, batch_size):\n",
    "        mndata = MNIST('samples')\n",
    "        images, labels = mndata.load_testing()\n",
    "\n",
    "        def get_mean_error(images, lables, w_1, w_2, w_3):\n",
    "            error = []\n",
    "            for image, label in zip(images, lables):\n",
    "                error.append(self.errf_with_custom_weights(image, label, w_1, w_2, w_3))\n",
    "            mean_error = np.mean(np.array(error))\n",
    "            self.error.append(mean_error)\n",
    "            return mean_error\n",
    "\n",
    "        def get_mean_grad(images, lables):\n",
    "            n = len(images)\n",
    "            grad_w_1, grad_w_2, grad_w_3 = self.get_grad(images[0], labels[0])\n",
    "\n",
    "            for image, label in zip(images[1:], lables[1:]):\n",
    "                cur_grad_w_1, cur_grad_w_2, cur_grad_w_3 = self.get_grad(image, label)\n",
    "                grad_w_1 += cur_grad_w_1\n",
    "                grad_w_2 += cur_grad_w_2\n",
    "                grad_w_3 += cur_grad_w_3\n",
    "\n",
    "            grad_w_1 /= n\n",
    "            grad_w_2 /= n\n",
    "            grad_w_3 /= n\n",
    "\n",
    "            return grad_w_1, grad_w_2, grad_w_3\n",
    "\n",
    "        batch_num = len(images) // batch_size\n",
    "\n",
    "        for epoch in range(epochs_num):\n",
    "            sample_indexes = np.linspace(0, len(images) - 1, len(images))\n",
    "            shuffle(sample_indexes)\n",
    "            shuffled_images = [images[int(sample_indexes[i])] for i in range(len(sample_indexes))]\n",
    "            shuffled_labels = [labels[int(sample_indexes[i])] for i in range(len(sample_indexes))]\n",
    "\n",
    "            for current_batch_num in range(batch_num):\n",
    "                print(\"started batch\", current_batch_num)\n",
    "                from_index = current_batch_num * batch_size\n",
    "                to_index = (current_batch_num + 1) * batch_size\n",
    "\n",
    "                current_batch_images = shuffled_images[from_index: to_index]\n",
    "                current_batch_labels = shuffled_labels[from_index: to_index]\n",
    "\n",
    "                steps_in_gradient_descent = 5\n",
    "                alpha_0 = 10e5\n",
    "                eps = 0.3\n",
    "                beta = 0.1\n",
    "\n",
    "                # Compute step for gradient descent according to Armijo rule\n",
    "                def armijo(f, grad_w_1, grad_w_2, grad_w_3, alpha, eps, beta):\n",
    "                    is_step_ready = False\n",
    "                    f_0 = f(self.w_1, self.w_2, self.w_3)\n",
    "                    \n",
    "                    while not is_step_ready:\n",
    "                        if f(self.w_1 - alpha * grad_w_1,\n",
    "                             self.w_2 - alpha * grad_w_2,\n",
    "                             self.w_3 - alpha * grad_w_3) <= f_0 - eps * alpha * (np.sum(grad_w_1 ** 2) +\n",
    "                                                                                  np.sum(grad_w_2 ** 2) +\n",
    "                                                                                  np.sum(grad_w_3 ** 2)) ** (1 / 2):\n",
    "                            is_step_ready = True\n",
    "                        else:\n",
    "                            alpha *= beta\n",
    "                    return alpha\n",
    "\n",
    "                mean_error = lambda w_1, w_2, w_3: get_mean_error(current_batch_images, current_batch_labels, w_1, w_2,\n",
    "                                                                  w_3)\n",
    "\n",
    "                # Gradient descent\n",
    "                while steps_in_gradient_descent > 0:\n",
    "                    steps_in_gradient_descent -= 1\n",
    "                    grad_w_1, grad_w_2, grad_w_3 = get_mean_grad(current_batch_images, current_batch_labels)\n",
    "                    step = armijo(mean_error, grad_w_1, grad_w_2, grad_w_3, alpha_0, eps, beta)\n",
    "                    self.update_weights(grad_w_1, grad_w_2, grad_w_3, step)\n",
    "\n",
    "            print('Epoch {} processed, error = {}'.format(self.epoch_num, self.error[-1]))\n",
    "            self.epoch_num += 1\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        x = range(len(self.error))\n",
    "        y = self.error\n",
    "        ax.plot(x, y, label='Значение функции ошибок')\n",
    "        plt.grid()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 processed, error = 1.501984340806137\n",
      "Epoch 2 processed, error = 1.5018488683963855\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "perchik = Perceptron(28 * 28, 16, 16, 10, False)\n",
    "perchik.teach_stochastic(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
