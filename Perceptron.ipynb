{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer perceptron. Stochastic gradient descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Класс перцептрона\n",
    "Вход            -   столбец $ W_{in} \\;[ 784 \\times 1] $, $ 784 = 28 \\times 28 $ -- размер исходного изображения  \n",
    "Первый слой     -   столбец $ S_{1} \\; [16 \\times 1] $  \n",
    "Второй слой     -   столбец $ S_{2} \\; [10 \\times 1] $  \n",
    "Выходной слой   -   столбец $ W_{out} \\; [10 \\times 1] $  \n",
    "В выходном слое в элементе $W_{out}[i], i \\in [0,9]$ содержится оценка вероятности того, что на вход подано изображение числа $i$  \n",
    "В качестве функции активации используется сигмоида $\\sigma (x) = \\frac{1}{1 + e^{-x}}$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "class Perceptron:\n",
    "    # INFO\n",
    "    # Matrix sizes\n",
    "\n",
    "    # s_in:  [w_in_dim  x 1        ]\n",
    "    # w_1:   [w_1_dim   x w_in_dim ]\n",
    "    # w_2:   [w_2_dim   x w_1_dim  ]\n",
    "    # w_3:   [w_out_dim x w_2_dim  ]\n",
    "    # s_out: [w_out_dim x 1        ]\n",
    "\n",
    "    s_in_dim = 0  # size of input vector\n",
    "    w_1_dim = 0  # number of rows in 1st hidden layer\n",
    "    w_2_dim = 0  # number of rows in 2nd hidden layer\n",
    "    s_out_dim = 0  # size of output vector\n",
    "\n",
    "    layers = []  # [w_1, w_2, w_3]\n",
    "    w_1 = []  # matrix with coefficients in ->  1\n",
    "    w_2 = []  # matrix with coefficients 1  ->  2\n",
    "    w_3 = []  # matrix with coefficients 2  ->  out\n",
    "\n",
    "    delta_w_1 = []\n",
    "    delta_w_2 = []\n",
    "    delta_w_3 = []\n",
    "\n",
    "    eta = 0\n",
    "    test_num = 0  # 0 in the beginning of learning. Increases when picture is processed\n",
    "    epoch_num = 0  # 0 in the beginning of learning. Increases when the whole battery of test pictures is processed\n",
    "\n",
    "    error = []  # array of errors of all the tests\n",
    "\n",
    "    def act_func(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def __init__(self, s_in_dim, w_1_dim, w_2_dim, s_out_dim, is_continuation):\n",
    "        if is_continuation:\n",
    "            self.load_changes()\n",
    "        else:\n",
    "            self.s_in_dim = s_in_dim\n",
    "            self.w_1_dim = w_1_dim\n",
    "            self.w_2_dim = w_2_dim\n",
    "            self.s_out_dim = s_out_dim\n",
    "\n",
    "            self.w_1 = np.random.sample((w_1_dim, s_in_dim)) / 10000\n",
    "            self.w_2 = np.random.sample((w_2_dim, w_1_dim)) / 100\n",
    "            self.w_3 = np.random.sample((s_out_dim, w_2_dim)) / 10\n",
    "\n",
    "            self.delta_w_1 = np.zeros((w_1_dim, s_in_dim))\n",
    "            self.delta_w_2 = np.zeros((w_2_dim, w_1_dim))\n",
    "            self.delta_w_3 = np.zeros((s_out_dim, w_2_dim))\n",
    "\n",
    "            self.layers = [self.w_1, self.w_2, self.w_3]\n",
    "\n",
    "    def recognize(self, picture):\n",
    "        s_1 = self.act_func(self.w_1 @ picture)\n",
    "        s_2 = self.act_func(self.w_2 @ s_1)\n",
    "        s_out = self.act_func(self.w_3 @ s_2)\n",
    "        return np.argmax(s_out)\n",
    "\n",
    "    def get_output(self, picture):\n",
    "        picture = np.array(picture).reshape((len(picture), 1)) / 255\n",
    "        s_1 = self.act_func(self.w_1 @ picture)\n",
    "        s_2 = self.act_func(self.w_2 @ s_1)\n",
    "        s_out = self.act_func(self.w_3 @ s_2)\n",
    "        return s_out\n",
    "\n",
    "    def errf(self, picture, ans):\n",
    "        picture = np.array(picture).reshape((len(picture), 1)) / 255\n",
    "        s_1 = self.act_func(self.w_1 @ picture)\n",
    "        s_2 = self.act_func(self.w_2 @ s_1)\n",
    "        s_out = self.act_func(self.w_3 @ s_2)\n",
    "\n",
    "        indicators = np.zeros(self.s_out_dim)\n",
    "        indicators[ans] = 1\n",
    "\n",
    "        return np.linalg.norm(indicators - s_out) / 2\n",
    "\n",
    "    def errf_with_custom_weights(self, picture, ans, w_1, w_2, w_3):\n",
    "        picture = np.array(picture).reshape((len(picture), 1)) / 255\n",
    "        s_1 = self.act_func(w_1 @ picture)\n",
    "        s_2 = self.act_func(w_2 @ s_1)\n",
    "        s_out = self.act_func(w_3 @ s_2)\n",
    "\n",
    "        indicators = np.zeros(self.s_out_dim)\n",
    "        indicators[ans] = 1\n",
    "\n",
    "        return np.linalg.norm(indicators - s_out) / 2\n",
    "\n",
    "    def get_grad(self, picture, ans):\n",
    "        picture = np.array(picture).reshape((len(picture), 1)) / 255\n",
    "        s_1 = self.act_func(self.w_1 @ picture)\n",
    "        s_2 = self.act_func(self.w_2 @ s_1)\n",
    "        s_out = self.act_func(self.w_3 @ s_2)\n",
    "\n",
    "        indicators = np.zeros(self.s_out_dim)\n",
    "        indicators[ans] = 1\n",
    "\n",
    "        delta_3 = s_out * (s_out - np.ones(self.s_out_dim).reshape((self.s_out_dim, 1))) * (\n",
    "                indicators.reshape((self.s_out_dim, 1)) - s_out)\n",
    "        delta_2 = s_2 * (np.ones(len(s_2)).reshape((len(s_2), 1)) - s_2) * (self.w_3.T @ delta_3)\n",
    "        delta_1 = s_1 * (np.ones(len(s_1)).reshape((len(s_1), 1)) - s_1) * (self.w_2.T @ delta_2)\n",
    "\n",
    "        grad_w_3 = (s_2.reshape((self.w_2_dim, 1)) @ delta_3.reshape((1, self.s_out_dim))).T\n",
    "        grad_w_2 = (self.eta * s_1.reshape((self.w_1_dim, 1)) @ delta_2.reshape((1, self.w_2_dim))).T\n",
    "        grad_w_1 = (self.eta * picture @ delta_1.reshape((1, self.w_1_dim))).T\n",
    "\n",
    "        return grad_w_1, grad_w_2, grad_w_3\n",
    "\n",
    "    def back_propagation(self, picture, ans, alpha):\n",
    "        picture = np.array(picture).reshape((len(picture), 1)) / 255\n",
    "        s_1 = self.act_func(self.w_1 @ picture)\n",
    "        s_2 = self.act_func(self.w_2 @ s_1)\n",
    "        s_out = self.act_func(self.w_3 @ s_2)\n",
    "\n",
    "        indicators = np.zeros(self.s_out_dim)\n",
    "        indicators[ans] = 1\n",
    "\n",
    "        delta_3 = s_out * (s_out - np.ones(self.s_out_dim).reshape((self.s_out_dim, 1))) * (\n",
    "                indicators.reshape((self.s_out_dim, 1)) - s_out)\n",
    "        delta_2 = s_2 * (np.ones(len(s_2)).reshape((len(s_2), 1)) - s_2) * (self.w_3.T @ delta_3)\n",
    "        delta_1 = s_1 * (np.ones(len(s_1)).reshape((len(s_1), 1)) - s_1) * (self.w_2.T @ delta_2)\n",
    "\n",
    "        self.delta_w_3 = alpha * self.delta_w_3 + \\\n",
    "                         ((1 - alpha) * self.eta * s_2.reshape((self.w_2_dim, 1)) @ delta_3.reshape(\n",
    "                             (1, self.s_out_dim))).T\n",
    "        self.delta_w_2 = alpha * self.delta_w_2 + \\\n",
    "                         ((1 - alpha) * self.eta * s_1.reshape((self.w_1_dim, 1)) @ delta_2.reshape(\n",
    "                             (1, self.w_2_dim))).T\n",
    "        self.delta_w_1 = alpha * self.delta_w_1 + \\\n",
    "                         ((1 - alpha) * self.eta * picture @ delta_1.reshape((1, self.w_1_dim))).T\n",
    "\n",
    "        self.w_3 -= self.delta_w_3\n",
    "        self.w_2 -= self.delta_w_2\n",
    "        self.w_1 -= self.delta_w_1\n",
    "\n",
    "        self.error.append(np.linalg.norm(indicators - s_out) / 2)\n",
    "\n",
    "    def get_data(self):\n",
    "        with open(\"perceptron_data.json\", \"r\") as read_file:\n",
    "            data = json.load(read_file)\n",
    "            # update data\n",
    "            data[\"s_in_dim\"] = Perceptron.s_in_dim\n",
    "            data[\"w_1_dim\"] = Perceptron.w_1_dim\n",
    "            data[\"w_2_dim\"] = Perceptron.w_2_dim\n",
    "            data[\"s_out_dim\"] = Perceptron.s_out_dim\n",
    "            data[\"layers\"] = Perceptron.layers\n",
    "            data[\"w_1\"] = Perceptron.w_1\n",
    "            data[\"w_2\"] = Perceptron.w_2\n",
    "            data[\"w_3\"] = Perceptron.w_3\n",
    "            data[\"delta_w_1\"] = Perceptron.delta_w_1\n",
    "            data[\"delta_w_2\"] = Perceptron.delta_w_2\n",
    "            data[\"delta_w_3\"] = Perceptron.delta_w_3\n",
    "            data[\"eta\"] = Perceptron.eta\n",
    "            data[\"test_num\"] = Perceptron.test_num\n",
    "            data[\"epoch_num\"] = Perceptron.epoch_num\n",
    "            data[\"error\"] = Perceptron.error\n",
    "        return data\n",
    "\n",
    "    \n",
    "    def initial_state():\n",
    "        initial_state_dict = {\n",
    "        \"s_in_dim\": 0,\n",
    "        \"w_1_dim\": 0,\n",
    "        \"w_2_dim\": 0,\n",
    "        \"s_out_dim\": 0,\n",
    "        \"layers\": [],\n",
    "        \"w_1\": [],\n",
    "        \"w_2\": [],\n",
    "        \"w_3\": [],\n",
    "        \"delta_w_1\": [],\n",
    "        \"delta_w_2\": [],\n",
    "        \"delta_w_3\": [],\n",
    "        \"eta\": 0,\n",
    "        \"test_num\": 0,\n",
    "        \"epoch_num\": 0,\n",
    "        \"error\": []\n",
    "        }\n",
    "        return initial_state_dict\n",
    "    \n",
    "    \n",
    "    def save_state(self):\n",
    "        if os.path.exists(\"perceptron_data.json\"):\n",
    "            data = get_data(self)\n",
    "            with open(\"data_file4.json\", \"w\") as write_file:\n",
    "                write_file.write(json.dumps(data))\n",
    "        else:\n",
    "            with open(\"perceptron_data.json\", \"w\") as write_file:\n",
    "                write_file.write(json.dumps(initial_state))\n",
    "            data = get_data(self)\n",
    "            with open(\"data_file4.json\", \"w\") as write_file:\n",
    "                write_file.write(json.dumps(data))\n",
    "\n",
    "\n",
    "    def load_state(self):\n",
    "        with open(\"data_file4.json\", \"r\") as read_file:\n",
    "            data = json.load(read_file)\n",
    "            Perceptron.s_in_dim = data[\"s_in_dim\"]\n",
    "            Perceptron.w_1_dim = data[\"w_1_dim\"]\n",
    "            Perceptron.w_2_dim = data[\"w_2_dim\"]\n",
    "            Perceptron.s_out_dim = data[\"s_out_dim\"]\n",
    "            Perceptron.layers = data[\"layers\"]\n",
    "            Perceptron.w_1 = data[\"w_1\"]\n",
    "            Perceptron.w_2 = data[\"w_2\"]\n",
    "            Perceptron.w_3 = data[\"w_3\"]\n",
    "            Perceptron.delta_w_1 = data[\"delta_w_1\"]\n",
    "            Perceptron.delta_w_2 = data[\"delta_w_2\"]\n",
    "            Perceptron.delta_w_3 = data[\"delta_w_3\"]\n",
    "            Perceptron.eta = data[\"eta\"]\n",
    "            Perceptron.test_num = data[\"test_num\"]\n",
    "            Perceptron.epoch_num = data[\"epoch_num\"]\n",
    "            Perceptron.error = data[\"error\"]\n",
    "    def update_weights(self, grad_w_1, grad_w_2, grad_w_3, step):\n",
    "        self.w_1 -= step * grad_w_1\n",
    "        self.w_2 -= step * grad_w_2\n",
    "        self.w_3 -= step * grad_w_3\n",
    "\n",
    "    def teach_stochastic(self, epochs_num):\n",
    "        mndata = MNIST('samples')\n",
    "        images, labels = mndata.load_testing()\n",
    "\n",
    "        self.load_changes()\n",
    "        data = zip(images, labels)\n",
    "\n",
    "        for epoch in range(epochs_num):\n",
    "            self.eta = 1 / (self.epoch_num ** (1 / 2) + 1)\n",
    "            for image, label in data:\n",
    "                self.back_propagation(image, label, 0.1)\n",
    "                self.test_num += 1\n",
    "            self.save_changes()\n",
    "            self.epoch_num += 1\n",
    "            # self.test_num = 0\n",
    "            print('Epoch {} processed, error = {}'.format(self.epoch_num, self.error[-1]))\n",
    "\n",
    "            idx = np.linspace(0, len(images) - 1, len(images))\n",
    "            new_img = [images[int(idx[i])] for i in range(len(idx))]\n",
    "            new_lbl = [labels[int(idx[i])] for i in range(len(idx))]\n",
    "            data = zip(new_img, new_lbl)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        x = range(len(self.error))\n",
    "        y = self.error\n",
    "        ax.plot(x, y, label='Значение функции ошибок')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "    def teach_batch(self, epochs_num, batch_size):\n",
    "        mndata = MNIST('samples')\n",
    "        images, labels = mndata.load_testing()\n",
    "\n",
    "        def get_mean_error(images, lables, w_1, w_2, w_3):\n",
    "            error = []\n",
    "            for image, label in zip(images, lables):\n",
    "                error.append(self.errf_with_custom_weights(image, label, w_1, w_2, w_3))\n",
    "            mean_error = np.mean(np.array(error))\n",
    "            self.error.append(mean_error)\n",
    "            return mean_error\n",
    "\n",
    "        def get_mean_grad(images, lables):\n",
    "            n = len(images)\n",
    "            grad_w_1, grad_w_2, grad_w_3 = self.get_grad(images[0], labels[0])\n",
    "\n",
    "            for image, label in zip(images[1:], lables[1:]):\n",
    "                cur_grad_w_1, cur_grad_w_2, cur_grad_w_3 = self.get_grad(image, label)\n",
    "                grad_w_1 += cur_grad_w_1\n",
    "                grad_w_2 += cur_grad_w_2\n",
    "                grad_w_3 += cur_grad_w_3\n",
    "\n",
    "            grad_w_1 /= n\n",
    "            grad_w_2 /= n\n",
    "            grad_w_3 /= n\n",
    "\n",
    "            return grad_w_1, grad_w_2, grad_w_3\n",
    "\n",
    "        batch_num = len(images) // batch_size\n",
    "\n",
    "        for epoch in range(epochs_num):\n",
    "            sample_indexes = np.linspace(0, len(images) - 1, len(images))\n",
    "            shuffle(sample_indexes)\n",
    "            shuffled_images = [images[int(sample_indexes[i])] for i in range(len(sample_indexes))]\n",
    "            shuffled_labels = [labels[int(sample_indexes[i])] for i in range(len(sample_indexes))]\n",
    "\n",
    "            for current_batch_num in range(batch_num):\n",
    "                print(\"started batch\", current_batch_num)\n",
    "                from_index = current_batch_num * batch_size\n",
    "                to_index = (current_batch_num + 1) * batch_size\n",
    "\n",
    "                current_batch_images = shuffled_images[from_index: to_index]\n",
    "                current_batch_labels = shuffled_labels[from_index: to_index]\n",
    "\n",
    "                steps_in_gradient_descent = 5\n",
    "                alpha_0 = 10e5\n",
    "                eps = 0.3\n",
    "                beta = 0.1\n",
    "\n",
    "                # Compute step for gradient descent according to Armijo rule\n",
    "                def armijo(f, grad_w_1, grad_w_2, grad_w_3, alpha, eps, beta):\n",
    "                    is_step_ready = False\n",
    "                    f_0 = f(self.w_1, self.w_2, self.w_3)\n",
    "                    \n",
    "                    while not is_step_ready:\n",
    "                        if f(self.w_1 - alpha * grad_w_1,\n",
    "                             self.w_2 - alpha * grad_w_2,\n",
    "                             self.w_3 - alpha * grad_w_3) <= f_0 - eps * alpha * (np.sum(grad_w_1 ** 2) +\n",
    "                                                                                  np.sum(grad_w_2 ** 2) +\n",
    "                                                                                  np.sum(grad_w_3 ** 2)) ** (1 / 2):\n",
    "                            is_step_ready = True\n",
    "                        else:\n",
    "                            alpha *= beta\n",
    "                    return alpha\n",
    "\n",
    "                mean_error = lambda w_1, w_2, w_3: get_mean_error(current_batch_images, current_batch_labels, w_1, w_2,\n",
    "                                                                  w_3)\n",
    "\n",
    "                # Gradient descent\n",
    "                while steps_in_gradient_descent > 0:\n",
    "                    steps_in_gradient_descent -= 1\n",
    "                    grad_w_1, grad_w_2, grad_w_3 = get_mean_grad(current_batch_images, current_batch_labels)\n",
    "                    step = armijo(mean_error, grad_w_1, grad_w_2, grad_w_3, alpha_0, eps, beta)\n",
    "                    self.update_weights(grad_w_1, grad_w_2, grad_w_3, step)\n",
    "\n",
    "            print('Epoch {} processed, error = {}'.format(self.epoch_num, self.error[-1]))\n",
    "            self.epoch_num += 1\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        x = range(len(self.error))\n",
    "        y = self.error\n",
    "        ax.plot(x, y, label='Значение функции ошибок')\n",
    "        plt.grid()\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
